{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e4aae3-61b4-4fe2-b7e3-f9939f5ae7f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f87188b-cce1-451a-8d1f-47f961c60dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = 0\n",
    "if (colab):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  import sys\n",
    "  sys.path.append(\"/content/drive/My Drive/Courses/DeepLearning/Project\")\n",
    "\n",
    "## Python Files\n",
    "!pip install mat73\n",
    "import utils\n",
    "import datas\n",
    "import models\n",
    "\n",
    "## Libraries\n",
    "import os  # when loading file paths\n",
    "\n",
    "from PIL import Image  # Load img\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import statistics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7eead4-726d-4b95-a685-04881f150770",
   "metadata": {},
   "source": [
    "### Setting up GPU Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ea4ff1-e174-4076-bc2b-d8a119485399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d68df1-e8a8-4685-973a-2b2dd43371aa",
   "metadata": {},
   "source": [
    "### Convert .mat to .png images for memory managment during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0350889-4717-4424-a50a-932aa44f3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2dataset = \"nyu_depth_v2_labeled.mat\"\n",
    "# utils.mat2png(path2dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89795af-ac4e-45be-b437-45cd4909288b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0585eb77-f605-4fc7-9aba-668734bfae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import datas\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "root_folder = \"Datas\"\n",
    "\n",
    "transform = get_transform(train=True)\n",
    "\n",
    "train_loader, test_loader = datas.get_loader(root_folder, batch_size=32, num_datas=1449, train_test_ratio=0.9, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa57a0-6658-4470-9dd0-0dddf80002d0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "193cd772-d3d1-4c99-a53a-4e6572630100",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "num_classes = 894\n",
    "object_detector = models.ObjectDetector(num_classes=num_classes).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "params = [p for p in object_detector.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=learning_rate,\n",
    "                            momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c35682-4f48-43f2-b323-0ffa23d7802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"/content/drive/My Drive/Courses/DeepLearning/Project/ODModel.pth.tar\"\n",
    "logs_path = \"/content/drive/My Drive/Courses/DeepLearning/Project/Logs.txt\"\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    object_detector.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "def save_checkpoint(state, filename=model_save_dir):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def write_log(file_path, stat):\n",
    "  with open(file_path, 'a') as f:\n",
    "    f.write(\"{0}\\n\".format(stat))\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "load_model = 0\n",
    "save_model = 1\n",
    "\n",
    "if load_model:\n",
    "      load_checkpoint(torch.load(model_save_dir), object_detector, optimizer)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logs = train_one_epoch(object_detector, optimizer, train_loader, device, epoch, print_freq=5, logs_path=logs_path)\n",
    "    evaluate(object_detector, test_loader, device=device)\n",
    "    if save_model:\n",
    "          checkpoint = {\n",
    "              \"state_dict\": object_detector.state_dict(),\n",
    "              \"optimizer\": optimizer.state_dict(),\n",
    "              }\n",
    "          save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ac0af5e-1f7b-4a02-9b18-12309a9d9090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], size=(0, 4)),\n",
       "  'labels': tensor([], dtype=torch.int64),\n",
       "  'scores': tensor([]),\n",
       "  'masks': tensor([], size=(0, 1, 480, 640))}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick one image from the test set\n",
    "images, targets = next(iter(train_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "img = images[3]\n",
    "# put the model in evaluation mode\n",
    "object_detector.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = object_detector([img.to(device)])\n",
    "    \n",
    "plt.imshow(img.permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d67c8-dfeb-4530-8c29-d833d0d5edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img = 0\n",
    "for obj in range(15):\n",
    "  plot_img = plot_img + prediction[0]['masks'][obj, 0].mul(255)\n",
    "plt.imshow(plot_img.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
